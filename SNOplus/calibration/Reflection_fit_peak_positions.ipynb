{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TClass::TClass:0: RuntimeWarning: no dictionary for class omtext is available\n"
     ]
    }
   ],
   "source": [
    "import ROOT, rat\n",
    "import os, sys, pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "%matplotlib inline \n",
    "sys.path.append('/home/jp/projects/snoplus/python_modules')\n",
    "import jp_mpl as jplot\n",
    "import geo_studies, rat_misc\n",
    "from scipy import ndimage\n",
    "reload(rat_misc)\n",
    "from scipy import signal\n",
    "from matplotlib.colors import LogNorm\n",
    "from detect_peaks import detect_peaks\n",
    "import pickle, scipy\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is AIRPLANE MODE - be careful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TClass::TClass:0: RuntimeWarning: no dictionary for class RAT::DBTableKey is available\n"
     ]
    }
   ],
   "source": [
    "# Airplane mode\n",
    "db = rat.RAT.DB.Get()\n",
    "db.SetAirplaneModeStatus(True)\n",
    "db.SetDefaultPlaneLockStatus(False)\n",
    "print 'This is AIRPLANE MODE - be careful!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "socdir = '/home/jp/projects/snoplus/laserball_calibration/all_runs'\n",
    "peakdir = '/home/jp/projects/snoplus/laserball_calibration/peak_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 SOC_0000017377_reprocessed.root\n",
      "1 SOC_0000017375_reprocessed.root\n",
      "2 SOC_0000017378_reprocessed.root\n",
      "3 SOC_0000100558.root\n",
      "4 SOC_0000100559.root\n",
      "5 SOC_0000100560.root\n",
      "6 SOC_0000100554.root\n",
      "7 SOC_0000017386_reprocessed.root\n",
      "8 SOC_0000100556.root\n",
      "9 SOC_0000017376_reprocessed.root\n",
      "10 SOC_0000100555.root\n",
      "11 SOC_0000017384_reprocessed.root\n"
     ]
    }
   ],
   "source": [
    "infile_list = os.listdir(socdir)\n",
    "for i, x in enumerate(infile_list): print i, x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bin_width = 0.5\n",
    "npmts = 9728"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTimeDiff(time_array,\n",
    "                bin_width=0.5,\n",
    "                twindow = [110, 220],\n",
    "                plot = False):\n",
    "    ybins  = np.linspace(0, 300, (300/bin_width)+1)\n",
    "    smooth_coeff = 1./(ybins[1]-ybins[0])\n",
    "    \n",
    "    # Finding the peak positions\n",
    "    n, x = np.histogram(time_array, ybins)\n",
    "    nsmooth = ndimage.filters.gaussian_filter1d(n, sigma=smooth_coeff)\n",
    "    \n",
    "    # Will use log(n) - zeros go away\n",
    "    nsmooth[nsmooth<=0] = 1\n",
    "\n",
    "    # Peak finding algorithm\n",
    "    peaks = detect_peaks(nsmooth, \n",
    "                         mpd = 10*smooth_coeff,\n",
    "                         edge='rising',show=False, mph=1.1)\n",
    "    \n",
    "    # Obtain the highest peak\n",
    "    highest_peak = peaks[nsmooth[peaks].argmax()]\n",
    "    # Obtain the latest peak\n",
    "    latest_peak = peaks[ybins[peaks].argmax()]\n",
    "    # Getting the time difference between highest ones\n",
    "    tdiff_peak = ybins[latest_peak] - ybins[highest_peak]\n",
    "    \n",
    "    # Finding the peaks of the derivative\n",
    "    dx = (ybins[1]-ybins[0])/2.\n",
    "    dn = np.diff(np.log10(n))/dx\n",
    "    ydn = ybins[1:-1]\n",
    "\n",
    "    # Derivating, and smoothing over it\n",
    "    dnsmooth = np.diff(np.log10(nsmooth))/dx  \n",
    "    dnsmooth = ndimage.filters.gaussian_filter1d(dnsmooth, \n",
    "                                                 sigma=smooth_coeff)\n",
    "\n",
    "    dpeaks = detect_peaks(dnsmooth, mpd = 10*smooth_coeff,\n",
    "                          edge='rising',show=False, mph=0.1)\n",
    "    \n",
    "    # Obtain the highest peak\n",
    "    highest_dpeak = dpeaks[dnsmooth[dpeaks].argmax()]\n",
    "    # Obtain the latest peak\n",
    "    latest_dpeak = dpeaks[ydn[dpeaks].argmax()]\n",
    "    # Getting the time difference between highest ones\n",
    "    tdiff_dpeak = ydn[latest_dpeak] - ydn[highest_dpeak]\n",
    "\n",
    "    if plot:\n",
    "        fig = plt.figure(figsize=(8,8))\n",
    "        ax1 = fig.add_subplot(211)\n",
    "        jplot.unfilledBar(ybins, n)\n",
    "        jplot.unfilledBar(ybins, nsmooth, color='red')\n",
    "        plt.yscale('log')\n",
    "        plt.plot((ybins[dpeaks]+ybins[dpeaks-1])/2., \n",
    "                 nsmooth[dpeaks], 'xg')\n",
    "        \n",
    "        used_peaks = np.array([highest_peak, latest_peak])\n",
    "        plt.plot(ybins[used_peaks], nsmooth[used_peaks], 'ok')\n",
    "        ax2 = fig.add_subplot(212,sharex=ax1)\n",
    "        plt.plot(ydn, dn, color = 'blue')\n",
    "\n",
    "        plt.plot(ydn, dnsmooth, color = 'red')\n",
    "        plt.subplots_adjust(hspace=0.)\n",
    "        plt.xlim(twindow)\n",
    "        used_dpeaks = np.array([highest_dpeak, latest_dpeak])\n",
    "\n",
    "        plt.plot((ydn[dpeaks]+ydn[dpeaks-1])/2., \n",
    "                  dnsmooth[dpeaks], 'xg')\n",
    "        plt.plot(ydn[used_dpeaks], dnsmooth[used_dpeaks], 'ok')\n",
    "        plt.show()\n",
    "        #raw_input()\n",
    "    return tdiff_peak, tdiff_dpeak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run SOC_0000017377_reprocessed.root\n",
      "Run already processed. Skipping it ...\n",
      "Adding SOC PMTs list\n",
      "Run SOC_0000017375_reprocessed.root\n",
      "Run already processed. Skipping it ...\n",
      "Adding SOC PMTs list\n",
      "Run SOC_0000017378_reprocessed.root\n",
      "Run already processed. Skipping it ...\n",
      "Adding SOC PMTs list\n",
      "Run SOC_0000100558.root\n",
      "Run already processed. Skipping it ...\n",
      "Adding SOC PMTs list\n",
      "Run SOC_0000100559.root\n",
      "Run already processed. Skipping it ...\n",
      "Adding SOC PMTs list\n",
      "Run SOC_0000100560.root\n",
      "Run already processed. Skipping it ...\n",
      "Adding SOC PMTs list\n",
      "Run SOC_0000100554.root\n",
      "Run already processed. Skipping it ...\n",
      "Adding SOC PMTs list\n",
      "Run SOC_0000017386_reprocessed.root\n",
      "Run already processed. Skipping it ...\n",
      "Adding SOC PMTs list\n",
      "Run SOC_0000100556.root\n",
      "Run already processed. Skipping it ...\n",
      "Adding SOC PMTs list\n",
      "Run SOC_0000017376_reprocessed.root\n",
      "Run already processed. Skipping it ...\n",
      "Adding SOC PMTs list\n",
      "Run SOC_0000100555.root\n",
      "Run already processed. Skipping it ...\n",
      "Adding SOC PMTs list\n",
      "Run SOC_0000017384_reprocessed.root\n",
      "Run already processed. Skipping it ...\n",
      "Adding SOC PMTs list\n"
     ]
    }
   ],
   "source": [
    "for one_infile in infile_list:\n",
    "    infile_name = os.path.join(socdir, one_infile)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print 'Run', one_infile\n",
    "    reader = rat.socreader(infile_name)\n",
    "    soc, run = reader.next()\n",
    "    soc.GetRunID()\n",
    "    \n",
    "    outfile_name = os.path.join(peakdir, \"%i\" % soc.GetRunID()+ '.pckl')\n",
    "    if os.path.isfile(outfile_name):\n",
    "        print 'Run already processed. Skipping it ...'\n",
    "        \n",
    "        data = pickle.load(open(outfile_name))\n",
    "        if not data.has_key('soc_pmts'):\n",
    "            data['soc_pmts'] = np.array(soc.GetSOCPMTIDs())\n",
    "            pickle.dump(data, open(outfile_name,'w'))\n",
    "            print 'Adding SOC PMTs list'\n",
    "        \n",
    "        reader.close()\n",
    "        continue\n",
    "    # Open the file\n",
    "\n",
    "    soc_pmts = np.array(soc.GetSOCPMTIDs())\n",
    "    \n",
    "    manip_pos = np.array(soc.calib.GetPos())\n",
    "    fit_pos = np.array(soc.GetFitResult(soc.GetFitNames()[0]).GetVertex(0).GetPosition())\n",
    "\n",
    "    \n",
    "    data = {'manip_pos':manip_pos,\n",
    "            'fit_pos':fit_pos,\n",
    "            'soc_pmts':soc_pmts}\n",
    "    \n",
    "\n",
    "    zero_counter = 0\n",
    "    skip_counter = 0\n",
    "    \n",
    "    delta_ts = np.zeros([npmts, 2])\n",
    "    print 'Going over the ', len(soc_pmts), ' PMTs'\n",
    "\n",
    "    for ipmt, one_pmt in enumerate(soc_pmts):\n",
    "        time_array = np.array(soc.GetSOCPMT(one_pmt).GetTimes())\n",
    "        if ipmt % 500 == 0:\n",
    "            print ipmt,\n",
    "        time_array[time_array < 0] = 0.\n",
    "        if time_array.mean() == 0 or time_array.size < 1000 or np.sum(time_array>0) < 1000:\n",
    "            skip_counter += 1\n",
    "            continue\n",
    "\n",
    "        delta_ts[one_pmt, :] = getTimeDiff(time_array,\n",
    "                                            bin_width = bin_width)\n",
    "        if np.sum(delta_ts[one_pmt,:]) == 0:\n",
    "            zero_counter += 1\n",
    "\n",
    "            \n",
    "    data['delta_ts'] = delta_ts\n",
    "    pickle.dump(data, open(outfile_name,'w'))\n",
    "    print 'Zero counter', zero_counter\n",
    "    print 'Skip counter', skip_counter\n",
    "    \n",
    "    reader.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
