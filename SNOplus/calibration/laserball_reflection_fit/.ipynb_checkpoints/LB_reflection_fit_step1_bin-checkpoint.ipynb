{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TClass::TClass:0: RuntimeWarning: no dictionary for class omtext is available\n"
     ]
    }
   ],
   "source": [
    "import ROOT, rat\n",
    "import os, sys, pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "%matplotlib inline \n",
    "\n",
    "import jp_mpl as jplot\n",
    "import geo_studies, rat_misc\n",
    "\n",
    "from scipy import optimize\n",
    "reload(rat_misc)\n",
    "from matplotlib.colors import LogNorm\n",
    "import pickle\n",
    "\n",
    "# My tools\n",
    "import jp_analysis as analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is AIRPLANE MODE - be careful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TClass::TClass:0: RuntimeWarning: no dictionary for class RAT::DBTableKey is available\n"
     ]
    }
   ],
   "source": [
    "# Airplane mode\n",
    "db = rat.RAT.DB.Get()\n",
    "db.SetAirplaneModeStatus(True)\n",
    "db.SetDefaultPlaneLockStatus(False)\n",
    "print 'This is AIRPLANE MODE - be careful!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "socdir = '/sb/project/qbs-015-ac/jpyanez/data/SOC_files'\n",
    "histdir = '/sb/project/qbs-015-ac/jpyanez/data/SOC_histograms_python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npmts = 9728"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201 [200, 9728]\n"
     ]
    }
   ],
   "source": [
    "# First, bin the data\n",
    "\n",
    "bin_width   = 0.5 # in ns\n",
    "time_window = 100. # 100 ns is enough for all runs (at least central ones)\n",
    "start_time  = -10\n",
    "residual_axis = np.arange(start_time, time_window + start_time+ bin_width/2., bin_width)\n",
    "hist_size  = [residual_axis.size-1, npmts]\n",
    "\n",
    "\n",
    "print residual_axis.size, hist_size\n",
    "test_pmts = [304, 1002, 4035, 7932]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makeHistogram(local_time_array):\n",
    "        \n",
    "    #### Bin the TOA, but *first* subtract the time delay of maximum\n",
    "    \n",
    "    # Large ToA binning\n",
    "    \n",
    "    # Bin the ToA\n",
    "    ybins  = np.linspace(local_time_array.mean()-100., \n",
    "                         local_time_array.mean()+200, \n",
    "                         (300/bin_width)+1)\n",
    "    \n",
    "    # Y-centers\n",
    "    ycenters = (ybins[1:] + ybins[:-1])/2.\n",
    "    \n",
    "    # First histogram\n",
    "    n, x = np.histogram(local_time_array, ybins)\n",
    "    \n",
    "    # Find the highest peak time\n",
    "    prompt_peak_index = n.argmax()\n",
    "    prompt_peak_time  = ycenters[prompt_peak_index] \n",
    "  \n",
    "    # Now re-do the histogram minus this time\n",
    "    \n",
    "    h, x = np.histogram( local_time_array - prompt_peak_time, residual_axis )\n",
    "    \n",
    "    return h, prompt_peak_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "infile_list = os.listdir(socdir)\n",
    "#for i, x in enumerate(infile_list): print i, x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running over all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run SOC_0000017375_reprocessed.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000017376_reprocessed.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000017377_reprocessed.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000017378_reprocessed.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000017384_reprocessed.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000017386_reprocessed.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000100554.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000100555.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000100556.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000100558.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000100559.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000100560.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000101152.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000101153.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000101154_000.root  - Subruns 5\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000101155.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000101158.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000101159.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000101160.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000101161.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000101427_reprocessed_newPCA.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000101428_reprocessed_newPCA.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000101432_reprocessed_newPCA.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000101433_reprocessed_newPCA.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000101437_reprocessed_newPCA.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000102518.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000102521.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000102523.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run SOC_0000102526.root  - Subruns 1\n",
      "Run already processed. Skipping it ...\n",
      "\n",
      "Run"
     ]
    }
   ],
   "source": [
    "# Complicated because of subruns\n",
    "\n",
    "while len(infile_list) > 0:\n",
    "    one_file = infile_list[0]\n",
    "    data = None\n",
    "    \n",
    "    \n",
    "    # Need to establish if the file has subfiles\n",
    "    run_number = one_file[:14]\n",
    "    new_list   = []\n",
    "    for one_name in infile_list:\n",
    "        if run_number in one_name:\n",
    "            new_list.append(one_name)\n",
    "    for one_name in new_list:\n",
    "        infile_list.remove(one_name)\n",
    "        \n",
    "    \n",
    "\n",
    "    # Going over the new list that includes subruns, open all SOC files\n",
    "    reader_list = []\n",
    "    soc_list = []\n",
    "    zero_counter = 0\n",
    "    skip_counter = 0\n",
    "    soc_pmts = np.array([0])\n",
    "    already_processed = False\n",
    "    for i, this_name in enumerate(new_list):\n",
    "        infile_name = os.path.join(socdir, this_name)        \n",
    "        if i == 0:\n",
    "            print '\\nRun', this_name, ' - Subruns', len(new_list)\n",
    "            outfile_name = os.path.join(histdir, run_number + '.pckl')\n",
    "            if os.path.isfile(outfile_name):\n",
    "                print 'Run already processed. Skipping it ...'\n",
    "                already_processed = True\n",
    "                \n",
    "                break\n",
    "            else:\n",
    "                print outfile_name\n",
    "                \n",
    "        \n",
    "        # Need to open all the readers\n",
    "        reader_list.append(rat.socreader(infile_name))\n",
    "        this_soc, this_run = reader_list[-1].next()\n",
    "        soc_list.append(this_soc)\n",
    "        soc_pmts = np.concatenate((soc_pmts, np.array(this_soc.GetSOCPMTIDs())))\n",
    "\n",
    "        if i == 0:\n",
    "            # Get the basic info from the first file\n",
    "            manip_pos = np.array(this_soc.calib.GetPos())\n",
    "            fit_pos  = np.array(this_soc.GetFitResult(this_soc.GetFitNames()[0]).GetVertex(0).GetPosition())\n",
    "\n",
    "            data = {'manip_pos':manip_pos,\n",
    "                    'fit_pos':fit_pos,\n",
    "                    'soc_pmts':soc_pmts,\n",
    "                    'wavelength':this_soc.calib.GetMode()}\n",
    "    \n",
    "            time_residuals = np.zeros(hist_size)\n",
    "        \n",
    "            print 'Going over the ', len(soc_pmts), ' PMTs'\n",
    "                              \n",
    "    if already_processed:\n",
    "        continue     \n",
    "\n",
    "        \n",
    "    # Now that SOC files have been opened, fill the histogram\n",
    "    soc_pmts    = np.unique(soc_pmts)\n",
    "    pmt_delays  = np.zeros(npmts)\n",
    "\n",
    "        \n",
    "    for ipmt, one_pmt in enumerate(soc_pmts):\n",
    "        time_array = np.array([0])\n",
    "        for isoc, soc in enumerate(soc_list):\n",
    "            try:\n",
    "                this_array = np.array(soc.GetSOCPMT(one_pmt).GetTimes())\n",
    "                time_array = np.concatenate((time_array,\n",
    "                                             this_array[this_array > 0]))\n",
    "            except:\n",
    "                print 'PMT problematic', one_pmt, new_list[isoc]\n",
    "                continue\n",
    "                \n",
    "            if ipmt % 500 == 0:\n",
    "                print ipmt\n",
    "                \n",
    "        # PMT ready. Make histogram and store time delay\n",
    "        time_residuals[:, one_pmt], pmt_delays[one_pmt] =  makeHistogram(time_array)\n",
    "        \n",
    "    data['time_residuals'] = time_residuals\n",
    "    data['pmt_delays']     = pmt_delays\n",
    "    pickle.dump(data, open(outfile_name,'w'))\n",
    "    \n",
    "    for reader in reader_list:\n",
    "        reader.close()\n",
    "    \n",
    "    # Verification for one file\n",
    "    fig = plt.figure()\n",
    "    colors = ['b','r','g','m']\n",
    "    for iTest, pmtid in enumerate(test_pmts):\n",
    "        jplot.unfilledBar(residual_axis + data['pmt_delays'][pmtid],\n",
    "                          data['time_residuals'][:,pmtid], color = colors[iTest])\n",
    "    plt.yscale('log')\n",
    "    fig.savefig(outfile_name.rstrip('pckl') + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
